 ### Tokenizing input ###
/home/sabar/Desktop/nlp_project/jamr/tools/cdec/corpus/support/utf8-normalize.sh: Cannot find ICU uconv (http://site.icu-project.org/) ... falling back to iconv. Quality may suffer.
 ### Running NER system ###
~/Desktop/nlp_project/jamr/tools/IllinoisNerExtended ~/Desktop/nlp_project/jamr
Adding feature: Forms
Adding feature: Capitalization
Adding feature: WordTypeInformation
Adding feature: Affixes
Adding feature: PreviousTag1
Adding feature: PreviousTag2
Adding feature: PreviousTagPatternLevel1
Adding feature: PreviousTagPatternLevel2
Adding feature: PrevTagsForContext
Adding feature: PredictionsLevel1
Adding feature: GazetteersFeatures
Adding feature: BrownClusterPaths
Loading gazetteers....
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
	loading gazetteer:....ner-ext/KnownLists/known_nationalities.lst
	loading gazetteer:....ner-ext/KnownLists/known_names.big.lst
	loading gazetteer:....ner-ext/KnownLists/WikiPeople.lst
	loading gazetteer:....ner-ext/KnownLists/temporal_words.txt
	loading gazetteer:....ner-ext/KnownLists/WikiLocationsRedirects.lst
	loading gazetteer:....ner-ext/KnownLists/measurments.txt
	loading gazetteer:....ner-ext/KnownLists/WikiPeopleRedirects.lst
	loading gazetteer:....ner-ext/KnownLists/cardinalNumber.txt
	loading gazetteer:....ner-ext/KnownLists/WikiManMadeObjectNames.lst
	loading gazetteer:....ner-ext/KnownLists/known_corporations.lst
	loading gazetteer:....ner-ext/KnownLists/WikiCompetitionsBattlesEvents.lst
	loading gazetteer:....ner-ext/KnownLists/currencyFinal.txt
	loading gazetteer:....ner-ext/KnownLists/WikiOrganizationsRedirects.lst
	loading gazetteer:....ner-ext/KnownLists/WikiOrganizations.lst
	loading gazetteer:....ner-ext/KnownLists/known_place.lst
	loading gazetteer:....ner-ext/KnownLists/KnownNationalities.txt
	loading gazetteer:....ner-ext/KnownLists/Occupations.txt
	loading gazetteer:....ner-ext/KnownLists/WikiSongs.lst
	loading gazetteer:....ner-ext/KnownLists/WikiArtWorkRedirects.lst
	loading gazetteer:....ner-ext/KnownLists/known_title.lst
	loading gazetteer:....ner-ext/KnownLists/ordinalNumber.txt
	loading gazetteer:....ner-ext/KnownLists/known_name.lst
	loading gazetteer:....ner-ext/KnownLists/WikiManMadeObjectNamesRedirects.lst
	loading gazetteer:....ner-ext/KnownLists/WikiArtWork.lst
	loading gazetteer:....ner-ext/KnownLists/WikiSongsRedirects.lst
	loading gazetteer:....ner-ext/KnownLists/known_country.lst
	loading gazetteer:....ner-ext/KnownLists/WikiFilms.lst
	loading gazetteer:....ner-ext/KnownLists/WikiCompetitionsBattlesEventsRedirects.lst
	loading gazetteer:....ner-ext/KnownLists/known_jobs.lst
	loading gazetteer:....ner-ext/KnownLists/VincentNgPeopleTitles.txt
	loading gazetteer:....ner-ext/KnownLists/WikiFilmsRedirects.lst
	loading gazetteer:....ner-ext/KnownLists/known_state.lst
	loading gazetteer:....ner-ext/KnownLists/WikiLocations.lst
found 33 gazetteers
1288301 words added
95262 words added
85963 words added

Working parameters are:
	inferenceMethod=GREEDY
	beamSize=5
	thresholdPrediction=false
	predictionConfidenceThreshold=-1.0
	labelTypes
		PER		ORG		LOC		MISC
	logging=false
	debuggingLogPath=null
	forceNewSentenceOnLineBreaks=true
	keepOriginalFileTokenizationAndSentenceSplitting=false
	taggingScheme=BILOU
	tokenizationScheme=DualTokenizationScheme
	pathToModelFile=data/Models/CoNLL/finalSystemBILOU.model
Brown clusters resource: 
	-Path: brown-clusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt
	-WordThres=5
	-IsLowercased=false
Brown clusters resource: 
	-Path: brown-clusters/brownBllipClusters
	-WordThres=5
	-IsLowercased=false
Brown clusters resource: 
	-Path: brown-clusters/brown-rcv1.clean.tokenized-CoNLL03.txt-c1000-freq1.txt
	-WordThres=5
	-IsLowercased=false

Tagging file: /tmp/jamr-17317.snt.tmp
Reading model file : data/Models/CoNLL/finalSystemBILOU.model.level1
Reading model file : data/Models/CoNLL/finalSystemBILOU.model.level2
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
~/Desktop/nlp_project/jamr
 ### Running dependency parser ###
Adding annotator tokenize
Adding annotator ssplit
Adding annotator parse
Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... done [1.3 sec].
